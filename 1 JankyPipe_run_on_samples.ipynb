{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook was made to create (and submit jobs for) JankyPipe, a pipeline that takes fastq files as input of Mycobacterium tuberculosis isolates, aligns the reads to H37Rv and calls variants. The output is a VCF file, a lineage call and a Qualimap report. This notebook also submits a job that runs JankyPipe on all of the isolate in our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from slurmpy import Slurm\n",
    "import vcf\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to launch JankyPipe as a Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Launch_JankyPipe(fqf1 , fqf2 , tag , output_dir , scratch_dir , O2_SLURM_logs_dir):\n",
    "    \n",
    "    '''\n",
    "    This script launches a job to call variants for the input fastq files against H37Rv\n",
    "    using a number of packages. The important output (VCF, lineage info files, quality report)\n",
    "    is stored in the output directory while the intermediary files (SAMs, trimmed fastqs, BAM, etc)\n",
    "    are stored in a scratch directory.\n",
    "    '''\n",
    "    \n",
    "    #store all commands in a list\n",
    "    commands_list = []\n",
    "    \n",
    "    #change directory to scratch\n",
    "    commands_list.append( 'cd ' + scratch_dir )\n",
    "\n",
    "    ###################################\n",
    "    ### Load Necessary Modules ########\n",
    "    ###################################\n",
    "\n",
    "    #load perl\n",
    "    commands_list.append( 'module load perl/5.24.0' )\n",
    "\n",
    "    #load java\n",
    "    commands_list.append( 'module load java/jdk-1.8u112' )\n",
    "\n",
    "    #load BWA\n",
    "    commands_list.append( 'module load bwa/0.7.15' )\n",
    "\n",
    "    #load Samtools\n",
    "    commands_list.append( 'module load samtools/1.3.1' )\n",
    "\n",
    "    #load BCFtools\n",
    "    commands_list.append( 'module load bcftools/1.3.1' )\n",
    "\n",
    "    #load Picard\n",
    "    commands_list.append( 'module load picard/2.8.0' )\n",
    "\n",
    "    #Create Index files for Reference Genome\n",
    "    commands_list.append( 'mkdir RefGen' )\n",
    "\n",
    "    #copy reference genome over to RefGen folder\n",
    "    commands_list.append( 'cp /home/rv76/Farhat_Lab/Reference_Seqs/H37Rv/h37rv.fasta RefGen/TBRefGen.fasta' )\n",
    "\n",
    "    #change directory to RefGen folder\n",
    "    commands_list.append( 'cd RefGen' )\n",
    "\n",
    "    ###################################\n",
    "    ### Create Index Files for H37Rv ##\n",
    "    ###################################\n",
    "    commands_list.append( 'samtools faidx TBRefGen.fasta' )\n",
    "    commands_list.append( 'bwa index TBRefGen.fasta' )\n",
    "\n",
    "    RefGen = scratch_dir + '/RefGen/TBRefGen.fasta' #H37Rv reference\n",
    "\n",
    "    #go back to parent directory\n",
    "    commands_list.append( 'cd ..' )\n",
    "\n",
    "    ###################################\n",
    "    ### UnZip FastQ files #############\n",
    "    ###################################\n",
    "    fqf1_base_name = fqf1.split('/')[-1][0:-9]\n",
    "    fqf2_base_name = fqf2.split('/')[-1][0:-9]\n",
    "\n",
    "    #work with the unzipped files for the rest of the pipeline (after unzipping them)\n",
    "    fqf1_unzipped = scratch_dir + '/{}'.format(fqf1_base_name) + '.fastq'\n",
    "    fqf2_unzipped = scratch_dir + '/{}'.format(fqf2_base_name) + '.fastq'\n",
    "\n",
    "    commands_list.append( 'zcat {0} > {1}'.format(fqf1, fqf1_unzipped) )\n",
    "    commands_list.append( 'zcat {0} > {1}'.format(fqf2, fqf2_unzipped) )\n",
    "\n",
    "    #use the unzipped fastq files now\n",
    "    fqf1 = fqf1_unzipped\n",
    "    fqf2 = fqf2_unzipped\n",
    "\n",
    "    ####################################\n",
    "    ### PRINSEQ (trim reads) ##########\n",
    "    ###################################\n",
    "\n",
    "    #create directory for prinseq in output directory\n",
    "    commands_list.append( 'mkdir ' + output_dir + '/prinseq' )\n",
    "\n",
    "    commands_list.append( 'perl /n/data1/hms/dbmi/farhat/bin/prinseq-lite-0.20.4/prinseq-lite.pl -fastq {0} -fastq2 {1} -out_format 3 -out_good {2}/{3}-trimmed -out_bad null -log {4}/{3}-trimmed.log -min_qual_mean 20 -verbose'.format(fqf1, fqf2, scratch_dir, tag , output_dir+'/prinseq') )\n",
    "\n",
    "    #use newly trimmed fastq files now\n",
    "    fqf1 = scratch_dir + '/{}'.format(tag) + '-trimmed_1.fastq'\n",
    "    fqf2 = scratch_dir + '/{}'.format(tag) + '-trimmed_2.fastq'\n",
    "\n",
    "    ######################################\n",
    "    ### BWA (align reads to reference) ###\n",
    "    ######################################\n",
    "\n",
    "    #create SAM file\n",
    "    samfile = scratch_dir + '/{}.sam'.format(tag)\n",
    "\n",
    "    #run BWA\n",
    "    commands_list.append( 'bwa mem -M {3} {0} {1} > {2}'.format(fqf1 , fqf2 , samfile , RefGen) )\n",
    "\n",
    "    #####################################\n",
    "    ### PICARD (sort & convert to BAM) ##\n",
    "    #####################################\n",
    "\n",
    "    #create BAM file\n",
    "    bamfile = scratch_dir + '/{0}.sorted.bam'.format(tag)\n",
    "\n",
    "    commands_list.append( 'java -Xmx16G -jar /n/data1/hms/dbmi/farhat/bin/picard/picard/build/libs/picard.jar SortSam INPUT={0} OUTPUT={1} SORT_ORDER=coordinate'.format(samfile, bamfile) )\n",
    "\n",
    "    ####################################\n",
    "    ### PICARD (remove duplicates) ####\n",
    "    ###################################\n",
    "\n",
    "    #create BAM file with removed duplicates\n",
    "    drbamfile = bamfile.replace(\".bam\", \".duprem.bam\")\n",
    "\n",
    "    #remove duplicates from BAM file\n",
    "    commands_list.append( \"java -Xmx32G -jar /n/data1/hms/dbmi/farhat/bin/picard/picard/build/libs/picard.jar MarkDuplicates I={0} O={1} REMOVE_DUPLICATES=true M={2} ASSUME_SORT_ORDER=coordinate\".format(bamfile, drbamfile, drbamfile[:-4]+'.metrics') )\n",
    "\n",
    "    ####################################\n",
    "    ### SAMTOOLS (to index BAM file) ###\n",
    "    ####################################\n",
    "    \n",
    "    commands_list.append( \"samtools index {0}\".format(drbamfile) )\n",
    "    \n",
    "    ######################################\n",
    "    ### QUALIMAP (quality of BAM file) ###\n",
    "    ######################################\n",
    "    \n",
    "    #store quality report, pilon VCF & lineage call information all in Output directory\n",
    "    commands_list.append( 'cd ' + output_dir )\n",
    "    commands_list.append( 'mkdir QualiMap' ) #make a folder for pilon output in output directory\n",
    "    commands_list.append( 'unset DISPLAY' ) #unset JAVA virtual machine variable [http://qualimap.bioinfo.cipf.es/doc_html/faq.html]\n",
    "    commands_list.append( \"/n/data1/hms/dbmi/farhat/bin/qualimap_v2.2.1/qualimap bamqc -bam {0} --outdir {1} --outfile {2}.pdf --outformat PDF\".format(drbamfile, output_dir+'/QualiMap', tag+'_stats') )\n",
    "\n",
    "    ###################################\n",
    "    ### PILON (call variants) #########\n",
    "    ###################################\n",
    "    \n",
    "    #store quality report, pilon VCF & lineage call information all in Output directory\n",
    "    commands_list.append( 'mkdir pilon' ) #make a folder for pilon output in output directory\n",
    "    out_pilon_dir = output_dir + '/pilon/' #variable for pilon output path\n",
    "\n",
    "    commands_list.append( 'java -Xmx32G -jar /n/data1/hms/dbmi/farhat/bin/pilon/pilon-1.22.jar --genome {0} --bam {1} --output {2} --outdir {3} --variant'.format(RefGen, drbamfile, tag, out_pilon_dir) )\n",
    "\n",
    "    #####################################\n",
    "    ### Luca's LINEAGE CALLING script ###\n",
    "    #####################################\n",
    "\n",
    "    #create directory \n",
    "    commands_list.append( 'mkdir ' + scratch_dir + '/fast-lineage-caller/' )#make a folder for lineage call in output directory\n",
    "    commands_list.append( 'mkdir ' + output_dir + '/fast-lineage-caller/' )#make a folder for lineage call in scratch directory\n",
    "\n",
    "    #create VRT file\n",
    "    vrtfile = scratch_dir + '/fast-lineage-caller/{}.vrt'.format(tag)\n",
    "\n",
    "    commands_list.append( 'cd ' + scratch_dir + '/fast-lineage-caller' )#change directory to store output in scratch\n",
    "\n",
    "    #convert VCF to VRT\n",
    "    commands_list.append( 'vrtTools-vcf2vrt.py {0} {1} 1'.format(out_pilon_dir+tag+'.vcf', vrtfile) )\n",
    "\n",
    "    #call lineage with SNP database an VRT file\n",
    "    commands_list.append( 'cd ' + output_dir + '/fast-lineage-caller' )#change directory to store output in VCF output\n",
    "\n",
    "    commands_list.append( 'FastLineageCaller-assign2lineage.py /home/rv76/Bio_Pipelines/fast-lineage-caller-master/example/db_snps.tsv ' + vrtfile + ' &> ' + 'lineage_call.txt' )\n",
    "\n",
    "    ###############################################################################################################\n",
    "    ######################################## SUBMIT as a job to O2 ################################################\n",
    "    ###############################################################################################################\n",
    "    \n",
    "    #append all commands in a single string to be submitted as a job\n",
    "    JankyPipe_job = ''\n",
    "    for command_i in commands_list:\n",
    "        JankyPipe_job = JankyPipe_job + '\\n' + command_i\n",
    "    \n",
    "    #directory where you want output + error files\n",
    "    os.chdir(O2_SLURM_logs_dir)\n",
    "\n",
    "    job_name = tag\n",
    "\n",
    "    s = Slurm(job_name , {'partition':'short' , 'n':'1' , 't':'0-6:00:00' , 'mem-per-cpu':'36G' , 'mail-type':'FAIL' , 'mail-user':'roger_vargas@g.harvard.edu'})\n",
    "\n",
    "    #submits the job\n",
    "    job_id = s.run(JankyPipe_job)\n",
    "\n",
    "    print job_name  + ' : ' +  str(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull all relevant sequenced isolate and corresponding FastQ file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_annotation = pd.read_csv('/n/data1/hms/dbmi/farhat/Roger/dennis_mujuni_collaboration/annotation CSV files/sample_fastq_path_names.csv' , sep = ',').set_index('sample_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>fastq_files</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Undetermined</td>\n",
       "      <td>/n/data1/hms/dbmi/farhat/Roger/dennis_mujuni_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TC100810</td>\n",
       "      <td>/n/data1/hms/dbmi/farhat/Roger/dennis_mujuni_c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sample_id                                        fastq_files\n",
       "sample_num                                                                 \n",
       "0           Undetermined  /n/data1/hms/dbmi/farhat/Roger/dennis_mujuni_c...\n",
       "1               TC100810  /n/data1/hms/dbmi/farhat/Roger/dennis_mujuni_c..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_annotation.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sample_annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT RUN CELLS BELOW UNLESS YOU WANT TO RUN EVERY SAMPLE THROUGH JANKYPIPE AGAIN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create directories for each isolate and launch JankyPipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT PARENT DIRECTORIES \n",
    "\n",
    "--->   /n/scratch2/rv76/JankyPipe_dennis_mujuni_collaboration/intermediary_files\n",
    "\n",
    "[to store intermediate files (unzipped fastq, trimmed fastq, SAM, sorted BAM, etc)]\n",
    "\n",
    "\n",
    "--->   /n/data1/hms/dbmi/farhat/Roger/dennis_mujuni_collaboration/JankyPipe/output\n",
    "\n",
    "[to store final files (pilon VCF, lineage, QualiMap, trim logs)]\n",
    "\n",
    "\n",
    "--->   /n/data1/hms/dbmi/farhat/Roger/dennis_mujuni_collaboration/JankyPipe/O2_SLURM_logs\n",
    "\n",
    "[to store submitted SLURM script, and SLURM error & verbose logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2230933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0 : 2230933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2230938\n",
      "submitted: Submitted batch job 2230941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1 : 2230938\n",
      "S2 : 2230941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2230945\n",
      "submitted: Submitted batch job 2230950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 : 2230945\n",
      "S4 : 2230950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2230956\n",
      "submitted: Submitted batch job 2230958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S5 : 2230956\n",
      "S6 : 2230958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2230960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S7 : 2230960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2230963\n",
      "submitted: Submitted batch job 2230967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S8 : 2230963\n",
      "S9 : 2230967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2230973\n",
      "submitted: Submitted batch job 2230976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S10 : 2230973\n",
      "S11 : 2230976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2230981\n",
      "submitted: Submitted batch job 2230984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S12 : 2230981\n",
      "S13 : 2230984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2230990\n",
      "submitted: Submitted batch job 2230996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S14 : 2230990\n",
      "S15 : 2230996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2231003\n",
      "submitted: Submitted batch job 2231009\n",
      "submitted: Submitted batch job 2231013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S16 : 2231003\n",
      "S17 : 2231009\n",
      "S18 : 2231013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2231018\n",
      "submitted: Submitted batch job 2231026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S19 : 2231018\n",
      "S20 : 2231026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2231031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S21 : 2231031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2231038\n",
      "submitted: Submitted batch job 2231043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S22 : 2231038\n",
      "S23 : 2231043\n",
      "S24 : 2231049\n",
      "S25 : 2231054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 2231049\n",
      "submitted: Submitted batch job 2231054\n"
     ]
    }
   ],
   "source": [
    "for isolate_i in range(0 , np.shape(sample_annotation)[0]):\n",
    "    \n",
    "    isolate_fastq_paths = sample_annotation.loc[isolate_i , 'fastq_files']\n",
    "\n",
    "    #paths & names for fastq files\n",
    "    fqf1 = isolate_fastq_paths + '_L001_R1_001.fastq.gz'\n",
    "    fqf2 = isolate_fastq_paths + '_L001_R2_001.fastq.gz'\n",
    "\n",
    "    #get the tag ID for the fastq files (same as ID for fastq files)\n",
    "    tag = fqf1.split('/')[-1].split('_')[1]\n",
    "\n",
    "    #where pilon VCF and lineage information will be stored [LAB FOLDER]\n",
    "    output_dir = '/n/data1/hms/dbmi/farhat/Roger/dennis_mujuni_collaboration/JankyPipe/output/' + tag\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "        os.makedirs(output_dir)\n",
    "    elif not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    #where everything else happens (trimming, aligning, etc.) [SCRATCH FOLDER]\n",
    "    scratch_dir = '/n/scratch2/rv76/JankyPipe_dennis_mujuni_collaboration/intermediary_files/' + tag\n",
    "    if os.path.exists(scratch_dir):\n",
    "        shutil.rmtree(scratch_dir)\n",
    "        os.makedirs(scratch_dir)\n",
    "    elif not os.path.exists(scratch_dir):\n",
    "        os.makedirs(scratch_dir)\n",
    "\n",
    "    #store O2 job log files [LAB FOLDER]\n",
    "    O2_SLURM_logs_dir = '/n/data1/hms/dbmi/farhat/Roger/dennis_mujuni_collaboration/JankyPipe/O2_SLURM_logs/' + tag\n",
    "\n",
    "    if os.path.exists(O2_SLURM_logs_dir):\n",
    "        shutil.rmtree(O2_SLURM_logs_dir)\n",
    "        os.makedirs(O2_SLURM_logs_dir)\n",
    "    elif not os.path.exists(O2_SLURM_logs_dir):\n",
    "        os.makedirs(O2_SLURM_logs_dir)\n",
    "\n",
    "    #Launch JankyPipe after making necessary directories!!!\n",
    "    Launch_JankyPipe(fqf1 , fqf2 , tag , output_dir , scratch_dir , O2_SLURM_logs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Determine if jobs ran successfully or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_run = []\n",
    "\n",
    "for isolate_i in range(0 , np.shape(sample_annotation)[0]):\n",
    "\n",
    "    #get the tag ID for the fastq files (same as ID for fastq files)\n",
    "    tag = 'S' + str(sample_annotation.loc[0,:].name)\n",
    "\n",
    "    #where pilon VCF and lineage information will be stored [LAB FOLDER]\n",
    "    output_dir = '/n/data1/hms/dbmi/farhat/Roger/dennis_mujuni_collaboration/JankyPipe/output/' + tag\n",
    "    \n",
    "    #check to see 'Lineage Call' folder exists in the output directory (last thing that is run in JankyPipe)\n",
    "    if os.path.exists(output_dir + '/fast-lineage-caller/'):\n",
    "        \n",
    "        successful_run.append('yes')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        successful_run.append('no')\n",
    "        \n",
    "sample_annotation['successful_run'] = successful_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>fastq_files</th>\n",
       "      <th>successful_run</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sample_id, fastq_files, successful_run]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_annotation[sample_annotation.successful_run == 'no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-Run isolates through pipeline that hit a run-timelimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolates that don't have a lineage-call directory didn't finish running through pipeline\n",
    "sample_annotation_ReRun = sample_annotation[sample_annotation.successful_run == 'no']\n",
    "\n",
    "#if path already exists, remove current contents, then recreate empty directory\n",
    "#if path doesn't exist, create new directory\n",
    "\n",
    "for isolate_i in range(0 , np.shape(sample_annotation_ReRun)[0]):\n",
    "    \n",
    "    isolate_fastq_paths = sample_annotation_ReRun.loc[isolate_i , 'fastq_files']\n",
    "\n",
    "    #paths & names for fastq files\n",
    "    fqf1 = isolate_fastq_paths + '_L001_R1_001.fastq.gz'\n",
    "    fqf2 = isolate_fastq_paths + '_L001_R2_001.fastq.gz'\n",
    "\n",
    "    #get the tag ID for the fastq files (same as ID for fastq files)\n",
    "    tag = fqf1.split('/')[-1].split('_')[1]\n",
    "\n",
    "    #where pilon VCF and lineage information will be stored [LAB FOLDER]\n",
    "    output_dir = '/n/data1/hms/dbmi/farhat/Roger/dennis_mujuni_collaboration/JankyPipe/output/' + tag\n",
    "    \n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "        os.makedirs(output_dir)\n",
    "    elif not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    #where everything else happens (trimming, aligning, etc.) [SCRATCH FOLDER]\n",
    "    scratch_dir = '/n/scratch2/rv76/JankyPipe_dennis_mujuni_collaboration/intermediary_files/' + tag\n",
    "    \n",
    "    if os.path.exists(scratch_dir):\n",
    "        shutil.rmtree(scratch_dir)\n",
    "        os.makedirs(scratch_dir)\n",
    "    elif not os.path.exists(scratch_dir):\n",
    "        os.makedirs(scratch_dir)\n",
    "\n",
    "    #store O2 job log files [LAB FOLDER]\n",
    "    O2_SLURM_logs_dir = '/n/data1/hms/dbmi/farhat/Roger/dennis_mujuni_collaboration/JankyPipe/O2_SLURM_logs/' + tag\n",
    "\n",
    "    if os.path.exists(O2_SLURM_logs_dir):\n",
    "        shutil.rmtree(O2_SLURM_logs_dir)\n",
    "        os.makedirs(O2_SLURM_logs_dir)\n",
    "    elif not os.path.exists(O2_SLURM_logs_dir):\n",
    "        os.makedirs(O2_SLURM_logs_dir)\n",
    "\n",
    "    #Launch JankyPipe after making necessary directories!!!\n",
    "    Launch_JankyPipe(fqf1 , fqf2 , tag , output_dir , scratch_dir , O2_SLURM_logs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
